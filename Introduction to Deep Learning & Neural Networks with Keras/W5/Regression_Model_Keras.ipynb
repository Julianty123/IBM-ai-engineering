{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W4HuV6IYyhHh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### If you want to see the data of a csv file (https://cocl.us/concrete_data) with python, use something like this:"
      ],
      "metadata": {
        "id": "W4HuV6IYyhHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path of the CSV file\n",
        "file_path = 'concrete_data.csv'\n",
        "\n",
        "# Read the CSV file and load the data into a DataFrame\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Now you can work with the data in the DataFrame\n",
        "# For example, you can print the first few rows of the DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAE1jI60ojk7",
        "outputId": "02750ed5-dbbc-4f7b-dc8e-ffe90729f2d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
            "0   540.0                 0.0      0.0  162.0               2.5   \n",
            "1   540.0                 0.0      0.0  162.0               2.5   \n",
            "2   332.5               142.5      0.0  228.0               0.0   \n",
            "3   332.5               142.5      0.0  228.0               0.0   \n",
            "4   198.6               132.4      0.0  192.0               0.0   \n",
            "\n",
            "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
            "0            1040.0           676.0   28     79.99  \n",
            "1            1055.0           676.0   28     61.89  \n",
            "2             932.0           594.0  270     40.27  \n",
            "3             932.0           594.0  365     41.05  \n",
            "4             978.4           825.5  360     44.30  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A: Build a baseline model"
      ],
      "metadata": {
        "id": "51BemIjlscf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA-7hsMBnSbL",
        "outputId": "f4d4c0f7-b260-4f0f-b6f2-f236f190202c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Mean squared error mean: 61.710334899471924\n",
            "Mean squared error standard deviation: 29.148376880706856\n"
          ]
        }
      ],
      "source": [
        "# The code imports the necessary libraries, such as numpy, pandas, \n",
        "# sklearn, and keras, to perform model training and evaluation.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow import keras\n",
        "\n",
        "# Step 1: Load the data from the CSV file\n",
        "data = pd.read_csv('concrete_data.csv')\n",
        "\n",
        "# Separate the features (X) and the target variable (y)\n",
        "X = data.drop('Strength', axis=1)\n",
        "y = data['Strength']\n",
        "\n",
        "# Step 1 (continued): Randomly split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Step 2: Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train and evaluate the model 50 times\n",
        "mse_list = []\n",
        "epochs = 50\n",
        "\n",
        "for _ in range(50):\n",
        "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_list.append(mse)\n",
        "\n",
        "# Step 5: Calculate mean and standard deviation of mean squared errors\n",
        "mse_mean = np.mean(mse_list)\n",
        "mse_std = np.std(mse_list)\n",
        "\n",
        "print(\"Mean squared error mean:\", mse_mean)\n",
        "print(\"Mean squared error standard deviation:\", mse_std)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part B: Normalize the data"
      ],
      "metadata": {
        "id": "gezmcHkmshIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_normalized = (X - X.mean()) / X.std()\n",
        "\n",
        "# Step 1 (continued): Randomly split the normalized data into training and test sets\n",
        "X_train_norm, X_test_norm, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
        "\n",
        "# Step 2: Define the model architecture\n",
        "model_norm = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(X_train_norm.shape[1],)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model_norm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train and evaluate the model 50 times on normalized data\n",
        "mse_list_norm = []\n",
        "\n",
        "for _ in range(50):\n",
        "    model_norm.fit(X_train_norm, y_train, epochs=epochs, verbose=0)\n",
        "    y_pred_norm = model_norm.predict(X_test_norm)\n",
        "    mse_norm = mean_squared_error(y_test, y_pred_norm)\n",
        "    mse_list_norm.append(mse_norm)\n",
        "\n",
        "# Step 5: Calculate mean and standard deviation of mean squared errors for normalized data\n",
        "mse_mean_norm = np.mean(mse_list_norm)\n",
        "mse_std_norm = np.std(mse_list_norm)\n",
        "\n",
        "print(\"Mean squared error mean (normalized data):\", mse_mean_norm)\n",
        "print(\"Mean squared error standard deviation (normalized data):\", mse_std_norm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z3yP3cCsh68",
        "outputId": "6f771d2c-2781-4f06-f0e3-a8f159f50389"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Mean squared error mean (normalized data): 51.449883574484346\n",
            "Mean squared error standard deviation (normalized data): 49.19351424994701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part C: Increase the number of epochs"
      ],
      "metadata": {
        "id": "Tj_Qnacxslxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "# Part B (continued): Train and evaluate the model 50 times on normalized data with 100 epochs\n",
        "mse_list_norm_100_epochs = []\n",
        "\n",
        "for _ in range(50):\n",
        "    model_norm.fit(X_train_norm, y_train, epochs=epochs, verbose=0)\n",
        "    y_pred_norm_100_epochs = model_norm.predict(X_test_norm)\n",
        "    mse_norm_100_epochs = mean_squared_error(y_test, y_pred_norm_100_epochs)\n",
        "    mse_list_norm_100_epochs.append(mse_norm_100_epochs)\n",
        "\n",
        "# Step 5: Calculate mean and standard deviation of mean squared errors for normalized data with 100 epochs\n",
        "mse_mean_norm_100_epochs = np.mean(mse_list_norm_100_epochs)\n",
        "mse_std_norm_100_epochs = np.std(mse_list_norm_100_epochs)\n",
        "\n",
        "print(\"Mean squared error mean (normalized data, 100 epochs):\", mse_mean_norm_100_epochs)\n",
        "print(\"Mean squared error standard deviation (normalized data, 100 epochs):\", mse_std_norm_100_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD-hmCXLskkq",
        "outputId": "27292df0-1f38-4d95-f4ce-f4b1632dc863"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            "Mean squared error mean (normalized data, 100 epochs): 31.24902163087095\n",
            "Mean squared error standard deviation (normalized data, 100 epochs): 0.3291361991611763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part D: Increase the number of hidden layers"
      ],
      "metadata": {
        "id": "hevyLo5dsnmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_d = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(X_train_norm.shape[1],)),\n",
        "    keras.layers.Dense(10, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model_d.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train and evaluate the model 50 times on normalized data with increased hidden layers\n",
        "mse_list_norm_d = []\n",
        "\n",
        "for _ in range(50):\n",
        "    model_d.fit(X_train_norm, y_train, epochs=epochs, verbose=0)\n",
        "    y_pred_norm_d = model_d.predict(X_test_norm)\n",
        "    mse_norm_d = mean_squared_error(y_test, y_pred_norm_d)\n",
        "    mse_list_norm_d.append(mse_norm_d)\n",
        "\n",
        "# Step 5: Calculate mean and standard deviation of mean squared errors for normalized data with increased hidden layers\n",
        "mse_mean_norm_d = np.mean(mse_list_norm_d)\n",
        "mse_std_norm_d = np.std(mse_list_norm_d)\n",
        "\n",
        "print(\"Mean squared error mean (normalized data, increased hidden layers):\", mse_mean_norm_d)\n",
        "print(\"Mean squared error standard deviation (normalized data, increased hidden layers):\", mse_std_norm_d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjwQbXAQsoW8",
        "outputId": "91a7b346-3f5b-49b4-fbc8-65fd65e193b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Mean squared error mean (normalized data, increased hidden layers): 32.804755977063834\n",
            "Mean squared error standard deviation (normalized data, increased hidden layers): 7.095522995003166\n"
          ]
        }
      ]
    }
  ]
}